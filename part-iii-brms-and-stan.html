<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>EPINOR Annual Meeting 2021</title>
    <meta charset="utf-8" />
    <meta name="author" content="Øystein Sørensen" />
    <script src="libs/header-attrs-2.11/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# EPINOR Annual Meeting 2021
## Part III - Bayesian Analysis with R
### Øystein Sørensen
### University of Oslo
### 2021/11/02

---








# Outline for Part III

- An overview of tools for Bayesian analysis in R

- Stan, brms

- 15 minute break

- Hands-on exercises

---

# Fitting Bayesian Models

- Computation for Bayesian models requires more expertise than fitting frequentist models.

- [BUGS - Bayesian Inference Using Gibbs Sampling](https://www.mrc-bsu.cam.ac.uk/software/bugs/)
  
  - Early software, which you may encounter in older textbooks. Can be used, but no longer actively developed.
  
- [JAGS - Just Another Gibbs Sampler](https://mcmc-jags.sourceforge.io/)

  - Further development of BUGS, but no new releases last four years.
  
- [Stan](https://mc-stan.org/)

  - State-of-the-art tool for Bayesian computation.
  
  - Very active community.


---

# Fitting Bayesian Models

- Stan is a programming language of its own, definitely increasing the barrier for easy learning.

- Can use R packages that yield familiar syntax, translating R code into Stan code:

  - [rethinking](https://github.com/rmcelreath/rethinking)
  
  - [rstanarm](https://mc-stan.org/rstanarm/)
  
  - [brms](https://paul-buerkner.github.io/brms/)
  
- [You can also use Stan from Stata!](https://github.com/stan-dev/statastan)


---

# Stan?

.pull-left[
[Stanisław Ulam](https://en.wikipedia.org/wiki/Stanislaw_Ulam)

&gt; a Polish scientist in the fields of mathematics and nuclear physics. He participated in the Manhattan Project, originated the Teller–Ulam design of thermonuclear weapons, discovered the concept of the cellular automaton, invented the Monte Carlo method of computation, and suggested nuclear pulse propulsion
]
.pull-right[
&lt;img src="figures/Stanislaw_Ulam.jpg" height=400&gt;
]


---

# brms


```r
library(brms)
```

```
## Loading required package: Rcpp
```

```
## Loading 'brms' package (version 2.16.1). Useful instructions
## can be found by typing help('brms'). A more detailed introduction
## to the package is available through vignette('brms_overview').
```

```
## 
## Attaching package: 'brms'
```

```
## The following object is masked from 'package:stats':
## 
##     ar
```


.footnote[
Bürkner, Paul-Christian. “brms: An R Package for Bayesian Multilevel Models Using Stan.” Journal of Statistical Software 80, no. 1 (August 29, 2017): 1–28. https://doi.org/10.18637/jss.v080.i01.
Bürkner, Paul-Christian. “Advanced Bayesian Multilevel Modeling with the R Package Brms.” The R Journal 10, no. 1 (2018): 395–411. https://doi.org/10.32614/RJ-2018-017.
]

---

# Fitting a logistic regression model with brms


```r
dat &lt;- readRDS("data/bwt.rds")
head(dat)
```

```
## # A tibble: 6 × 5
##     Low   Age   LWT Smoker Hypertension
##   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt;       
## 1     0    19  82.6 FALSE  FALSE       
## 2     0    33  70.3 FALSE  FALSE       
## 3     0    20  47.6 TRUE   FALSE       
## 4     0    21  49.0 TRUE   FALSE       
## 5     0    18  48.5 TRUE   FALSE       
## 6     0    21  56.2 FALSE  FALSE
```


---

# Fitting a logistic regression model with brms

```r
mod &lt;- brm(Low ~ LWT, data = dat, family = bernoulli())
## Compiling Stan program...
## Start sampling
## 
## SAMPLING FOR MODEL 'd3c8392ac3fcb0c96e96bdaad5582435' NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 2.1e-05 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## ...
## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 0.058381 seconds (Warm-up)
## Chain 4:                0.054892 seconds (Sampling)
## Chain 4:                0.113273 seconds (Total)
## Chain 4: 
```


---

# Fitting a logistic regression model with brms



```r
mod &lt;- brm(Low ~ LWT, data = dat, family = bernoulli())
```

is very similar to


```r
mod_glm &lt;- glm(Low ~ LWT, data = dat, family = binomial())
```

- `family = binomial()` would work with brms too, but is not the standard syntax.

---

# Model output







```r
summary(mod)
```

```
##  Family: bernoulli 
##   Links: mu = logit 
## Formula: Low ~ LWT 
##    Data: dat (Number of observations: 189) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     1.07      0.79    -0.43     2.64 1.00     2793     2041
## LWT          -0.03      0.01    -0.06    -0.01 1.00     2600     2177
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).
```

---

class: inverse, middle, center

# Let's try to use the Bayesian workflow

---

# (a) Exploratory Data Analysis

- Important, but not particularly related to brms. 

---

# (b) Prior Distribution

In the previous lecture we decided on using a normal prior for `\(\beta_{LWT}\)` with mean 0 and standard deviation 0.4.

We start by getting the default prior:


```r
prior &lt;- get_prior(Low ~ LWT, family = bernoulli(), 
                   data = dat)
print(prior, show_df = FALSE)
```

```
## b ~ (flat)
## b_LWT ~ (flat)
## Intercept ~ student_t(3, 0, 2.5)
```

- "b" denotes all population-level parameters
- "b_LWT" denotes the particular LWT parameter
- "Intercept" is what it is.

---

# (b) Prior Distribution

Update to get what we want:


```r
prior$prior[2] &lt;- "normal(0, 0.4)"
```

--

Check that prior is updated:


```r
print(prior, show_df = FALSE)
```

```
## b ~ (flat)
## b_LWT ~ normal(0, 0.4)
## Intercept ~ student_t(3, 0, 2.5)
```

---

# (c) Check that the computations work correctly

Then we have to fit the model first, with our preferred prior:


```r
mod &lt;- brm(Low ~ LWT, data = dat, family = bernoulli(),
           prior = prior)
```







```
## Compiling Stan program...
```

```
## recompiling to avoid crashing R session
```

```
## Start sampling
```

```
## 
## SAMPLING FOR MODEL 'f53afefa5fd92239adec95c91ede857a' NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 2.2e-05 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.032954 seconds (Warm-up)
## Chain 1:                0.025207 seconds (Sampling)
## Chain 1:                0.058161 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL 'f53afefa5fd92239adec95c91ede857a' NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 1.2e-05 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.032529 seconds (Warm-up)
## Chain 2:                0.029446 seconds (Sampling)
## Chain 2:                0.061975 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL 'f53afefa5fd92239adec95c91ede857a' NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 1.1e-05 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.037319 seconds (Warm-up)
## Chain 3:                0.02989 seconds (Sampling)
## Chain 3:                0.067209 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL 'f53afefa5fd92239adec95c91ede857a' NOW (CHAIN 4).
## Chain 4: 
## Chain 4: Gradient evaluation took 1.1e-05 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 0.031868 seconds (Warm-up)
## Chain 4:                0.030694 seconds (Sampling)
## Chain 4:                0.062562 seconds (Total)
## Chain 4:
```


---

# (c) Check that computations work correctly


```r
plot(mod)
```

&lt;img src="part-iii-brms-and-stan_files/figure-html/unnamed-chunk-16-1.svg" style="display: block; margin: auto;" /&gt;

---

# (c) Check that computations work correctly


```r
plot(mod, combo = c("parcoord", "rank_overlay"))
```

&lt;img src="part-iii-brms-and-stan_files/figure-html/unnamed-chunk-17-1.svg" style="display: block; margin: auto;" /&gt;


---

# (c) Check that computations work correctly


```r
summary(mod)
```

```
##  Family: bernoulli 
##   Links: mu = logit 
## Formula: Low ~ LWT 
##    Data: dat (Number of observations: 189) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     1.07      0.79    -0.45     2.66 1.00     3536     2574
## LWT          -0.03      0.01    -0.06    -0.01 1.00     3189     2529
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).
```


---

# (d) Check that the model fits the data well


```r
pp_check(mod)
```

```
## Using 10 posterior draws for ppc type 'dens_overlay' by default.
```

&lt;img src="part-iii-brms-and-stan_files/figure-html/unnamed-chunk-19-1.svg" style="display: block; margin: auto;" /&gt;

---

# (d) Check that the model fits the data well


```r
pp_check(mod, type = "error_hist", ndraws = 11)
```

```
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
```

&lt;img src="part-iii-brms-and-stan_files/figure-html/unnamed-chunk-20-1.svg" style="display: block; margin: auto;" /&gt;

---

# (d) Check that the model fits the data well


```r
pp_check(mod, type = "scatter_avg")
```

```
## Using all posterior draws for ppc type 'scatter_avg' by default.
```

&lt;img src="part-iii-brms-and-stan_files/figure-html/unnamed-chunk-21-1.svg" style="display: block; margin: auto;" /&gt;

---

# (d) Check that the model fits the data well


```r
pp_check(mod, ndraws = 100, type = "bars")
```

&lt;img src="part-iii-brms-and-stan_files/figure-html/unnamed-chunk-22-1.svg" style="display: block; margin: auto;" /&gt;


---

# (e) Compare to other more or less complicated models

Extend the model by adding smoking status


```r
mod2 &lt;- brm(
  Low ~ LWT + Smoker, data = dat, 
  family = bernoulli(),
  prior = c(
    set_prior("normal(0, 0.4)", "b", coef = "LWT"),
    set_prior("normal(0, 2)", "b", coef = "SmokerTRUE")
  ))
```






---

# (e) Compare to other more or less complicated models


```r
plot(mod2)
```

&lt;img src="part-iii-brms-and-stan_files/figure-html/unnamed-chunk-26-1.svg" style="display: block; margin: auto;" /&gt;


---

# (e) Leave-one-out Cross-validation


```r
loo1 &lt;- loo(mod, model_names = "LWT")
loo2 &lt;- loo(mod2, model_names = "LWT+Smoker")
loo_compare(loo1, loo2)
```

```
##            elpd_diff se_diff
## LWT+Smoker  0.0       0.0   
## LWT        -1.1       2.1
```


---

# Examine the model outputs


```r
conditional_effects(mod)
```

&lt;img src="part-iii-brms-and-stan_files/figure-html/unnamed-chunk-28-1.png" style="display: block; margin: auto;" /&gt;

---

# Examine the model outputs


```r
conditional_effects(
  mod2, effects = "LWT",
  conditions = data.frame(Smoker = c(FALSE, TRUE),
                          cond__ = c("Non-smoker", "Smoker")))
```

&lt;img src="part-iii-brms-and-stan_files/figure-html/unnamed-chunk-29-1.png" style="display: block; margin: auto;" /&gt;

---

# Posterior intervals


```r
mcmc_plot(mod2)
```

&lt;img src="part-iii-brms-and-stan_files/figure-html/unnamed-chunk-30-1.png" style="display: block; margin: auto;" /&gt;

---

# Joint Posterior Density


```r
mcmc_plot(mod2, variable = c("b_LWT", "b_SmokerTRUE"), 
          type = "scatter")
```

&lt;img src="part-iii-brms-and-stan_files/figure-html/unnamed-chunk-31-1.svg" style="display: block; margin: auto;" /&gt;

---

# Joint Posterior Density


```r
mcmc_plot(mod2, type = "pairs")
```

&lt;img src="part-iii-brms-and-stan_files/figure-html/unnamed-chunk-32-1.svg" style="display: block; margin: auto;" /&gt;

---

# Joint Posterior Density

What's the probability the both `\(\beta_{LWT} &gt; 0\)` and `\(\beta_{Smoker} &lt; 0\)`, i.e., that smoking is protective and the probability of low birthweight increases with mother's weight?


```r
df &lt;- as_draws_df(mod2)
head(df)
```

```
## # A draws_df: 6 iterations, 1 chains, and 4 variables
##   b_Intercept   b_LWT b_SmokerTRUE lp__
## 1        0.77 -0.0270         0.44 -117
## 2       -0.58 -0.0075         0.78 -118
## 3        1.16 -0.0413         0.57 -117
## 4        0.40 -0.0265         0.82 -116
## 5        0.87 -0.0281         0.37 -117
## 6        1.80 -0.0455         0.16 -118
## # ... hidden reserved variables {'.chain', '.iteration', '.draw'}
```


---

# Joint Posterior Density

Let's do this carefully. First select columns.


```r
df %&gt;% 
  as_tibble() %&gt;% 
 select(b_LWT, b_SmokerTRUE)
```

```
## # A tibble: 4,000 × 2
##       b_LWT b_SmokerTRUE
##       &lt;dbl&gt;        &lt;dbl&gt;
##  1 -0.0270         0.444
##  2 -0.00754        0.783
##  3 -0.0413         0.567
##  4 -0.0265         0.823
##  5 -0.0281         0.372
##  6 -0.0455         0.164
##  7 -0.0175         1.13 
##  8 -0.0282         0.458
##  9 -0.0481         0.545
## 10 -0.0511         0.445
## # … with 3,990 more rows
```


---

# Joint Posterior Density

Label the ones that meet our criteria.


```r
df %&gt;% 
  as_tibble() %&gt;% 
  select(b_LWT, b_SmokerTRUE) %&gt;% 
  mutate(meets_criteria = b_LWT &gt; 0 &amp; b_SmokerTRUE &lt; 0)
```

```
## # A tibble: 4,000 × 3
##       b_LWT b_SmokerTRUE meets_criteria
##       &lt;dbl&gt;        &lt;dbl&gt; &lt;lgl&gt;         
##  1 -0.0270         0.444 FALSE         
##  2 -0.00754        0.783 FALSE         
##  3 -0.0413         0.567 FALSE         
##  4 -0.0265         0.823 FALSE         
##  5 -0.0281         0.372 FALSE         
##  6 -0.0455         0.164 FALSE         
##  7 -0.0175         1.13  FALSE         
##  8 -0.0282         0.458 FALSE         
##  9 -0.0481         0.545 FALSE         
## 10 -0.0511         0.445 FALSE         
## # … with 3,990 more rows
```


---

# Joint Posterior Density

Find the proportion of samples from posterior distribution that meets the criteria.


```r
df %&gt;% 
  as_tibble() %&gt;% 
  select(b_LWT, b_SmokerTRUE) %&gt;% 
  mutate(meets_criteria = b_LWT &gt; 0 &amp; b_SmokerTRUE &lt; 0) %&gt;% 
  summarise(proportion = mean(meets_criteria))
```

```
## # A tibble: 1 × 1
##   proportion
##        &lt;dbl&gt;
## 1          0
```

---

# Joint Posterior Density

What's the probability that the odds ratio associated with a 1 kg difference in mother's weight is between 0.99 and 1.01?


```r
df %&gt;% 
  as_tibble() %&gt;% 
  select(b_LWT) %&gt;% 
  mutate(
    odds_ratio = exp(b_LWT),
    meets_criteria = between(odds_ratio, .99, 1.01))
```

```
## # A tibble: 4,000 × 3
##       b_LWT odds_ratio meets_criteria
##       &lt;dbl&gt;      &lt;dbl&gt; &lt;lgl&gt;         
##  1 -0.0270       0.973 FALSE         
##  2 -0.00754      0.992 TRUE          
##  3 -0.0413       0.960 FALSE         
##  4 -0.0265       0.974 FALSE         
##  5 -0.0281       0.972 FALSE         
##  6 -0.0455       0.955 FALSE         
##  7 -0.0175       0.983 FALSE         
##  8 -0.0282       0.972 FALSE         
##  9 -0.0481       0.953 FALSE         
## 10 -0.0511       0.950 FALSE         
## # … with 3,990 more rows
```


---

# Joint Posterior Density

Find proportion that meets criteria


```r
df %&gt;% 
  as_tibble() %&gt;% 
  select(b_LWT) %&gt;% 
  mutate(
    odds_ratio = exp(b_LWT),
    meets_criteria = between(odds_ratio, .99, 1.01)) %&gt;% 
  summarise(proportion = mean(meets_criteria))
```

```
## # A tibble: 1 × 1
##   proportion
##        &lt;dbl&gt;
## 1     0.0582
```

This is the posterior probability that the odds ratio is between 0.99 and 1.01.

---

class: center, middle

# Thanks!

Slides created via the R package [**xaringan**](https://github.com/yihui/xaringan).

The chakra comes from [remark.js](https://remarkjs.com), [**knitr**](https://yihui.org/knitr/), and [R Markdown](https://rmarkdown.rstudio.com).
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
